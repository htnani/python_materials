{
 "metadata": {
  "name": "",
  "signature": "sha256:1cbe5b9d885df7048f3170917ae7fab753cd0bda419e8d6d04a183de37262ca9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext watermark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%watermark -a Schmelling,Nicolas -u -d -v -p biopython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Schmelling,Nicolas \n",
        "Last updated: 04/04/2015 \n",
        "\n",
        "CPython 2.7.8\n",
        "IPython 2.2.0\n",
        "\n",
        "matplotlib 1.4.0\n",
        "numpy 1.9.0\n",
        "pandas 0.14.1\n",
        "scipy 0.14.0\n",
        "biopython 1.65\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "Any comments and suggestions or questions?     \n",
      "Please feel free to contact me via [twitter](https://twitter.com/bio_mediocre) or [email](mailto:schmelli@msu.edu).\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Content#\n",
      "---\n",
      "\n",
      "| [DNA to Protein](#DNAtoProt) | [BLAST](#BLAST) | [Extracting sequences from XML files](#fasta) | [Command line BLAST](#BLAST back) | [Filtering hits by GI's](#filter) | [Writing CSV files from BLAST results](#CSV)\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Identify new plant-microbe genes\n",
      "----\n",
      "\n",
      "This project aims to investigate the "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import SeqIO\n",
      "from Bio.Blast import NCBIWWW\n",
      "from Bio.Blast import NCBIXML\n",
      "from Bio import Entrez\n",
      "\n",
      "from urllib2 import HTTPError\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast import NCBIWWW\n",
      "from Bio.Blast import NCBIXML\n",
      "from Bio import SeqIO\n",
      "from Bio import Phylo\n",
      "from Bio import AlignIO\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import ticker\n",
      "import glob\n",
      "import time\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as s\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='BLAST'></a>\n",
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###BLAST###\n",
      "---\n",
      "\n",
      "Before we get started with our BLAST run, we need a fasta file with our sequences. So either you copy/paste your sequences of interest in a new fasta file or you download a file that contains all your sequences. In my case I needed to get all sequences and create a new fasta file.      \n",
      "\n",
      "Your fasta file should look something like this:          \n",
      "\n",
      "`>fasta sequence header`     \n",
      "`sequence e.g. MASJINDHASDINEIHGNISD`      \n",
      "`>next sequence header`      \n",
      "`next sequence e.g. MINASIDJGHIENGISJDA`     "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I used the Biopython package for all BLAST related analysis and coding. For more information check www.biopython.org.\n",
      "# First we read our fasta file sequence by sequence. The SeqIO.parse function needs only a file name, but to make sure it reads\n",
      "# the file correct, we specify the file format.\n",
      "for seq_record in SeqIO.parse('D1_WP_010874309.faa', format='fasta'):\n",
      "    \n",
      "    # Next we send our sequence to NCBI server and use the BLAST online version. \n",
      "    # NCBIWWW takes a program argument: In our case blastp, b/c we blast protein against protein. \n",
      "    # a database argument: In our case nr, b/c we want to blast against almost all protein sequences.\n",
      "    # a format argument: Just to make sure BLAST reads our sequences correctly.\n",
      "    # and various additional arguments (optinal): expect = e-value (cut off value, for less similarity), \n",
      "                                                # hitlist_size = no. of maximum hits\n",
      "                                                # matrix_name and word_size are the default values.\n",
      "    result_handle = NCBIWWW.qblast('blastp', 'nr', seq_record.format('fasta'), expect=0.00001,\n",
      "                                   hitlist_size=10, matrix_name='BLOSUM62', word_size=3)\n",
      "    \n",
      "    # We save the BLAST result for every sequence in a new XML file, for later parsing.\n",
      "    # First we need to open a new file with a descriptive name (sequence name seems like a good idea)\n",
      "    # Then we write the results in the file and don't forget to close it afterwards.\n",
      "    # In the end we also close the BLAST result file, before we go on to the next sequence\n",
      "    save_file = open('D1_BLAST.xml', 'w')\n",
      "    save_file.write(result_handle.read())\n",
      "    save_file.close()\n",
      "    result_handle.close()   \n",
      "# This script can run a while, depending on the no. of sequences in your file and your hitlist_size value."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='fasta'></a>\n",
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Write fasta file from XML BLAST results###\n",
      "---\n",
      "\n",
      "Before we can start the next BLAST run we need to extract the amino acid sequences from the hits, we obtained in the first run, and write them into a fasta file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Entrez.email ='schmelli@msu.edu'\n",
      "\n",
      "result_handle = open('D1_BLAST.xml')\n",
      "blast_record = NCBIXML.read(result_handle)\n",
      "    \n",
      "# We now want to write a fasta file, b/c we need the sequences for our next BLAST run.\n",
      "# The suffix .faa is just a more precise fasta file (amino acid fasta file).\n",
      "save_file = open('D1_BLAST.faa', 'w')\n",
      "\n",
      "# Now we go through each record in the XML and each alingment of these records. In our case the record is the protein\n",
      "# sequence we used a template for the BLAST analysis. The alingment are each match with the nr database.\n",
      "# We want to write a fasta file, so we need the sequence name as a header. As mentioned above every fasta header starts with\n",
      "# a >.\n",
      "# Next we write the sequence of this hit. We have to replace possible dashes b/c BLAST inserts them to indicate caps in the\n",
      "# alignment. Sometime there are multiple alignments for one hit, b/c substrings of the sequence align partly (I think).\n",
      "# Nevertheless the first align is also the longest and best. This allows us the break the loop the first sequence and go on \n",
      "# to the next alignment.\n",
      "for alignment in blast_record.alignments:\n",
      "    save_file.write('>' + alignment.title + '\\n')\n",
      "    line = str(alignment.title.split('|',2)[1])\n",
      "    try:\n",
      "        handle = Entrez.efetch(db='protein', id=line, retmode='xml')\n",
      "    except HTTPError:\n",
      "        time.sleep(20)\n",
      "        handle = Entrez.efetch(db='protein', id=line, retmode='xml')\n",
      "    records = Entrez.read(handle)\n",
      "    save_file.write(records[0]['GBSeq_sequence'].upper() + '\\n')\n",
      "    time.sleep(1) # to make sure not many requests go per second to ncbi\n",
      "\n",
      "save_file.close()\n",
      "result_handle.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='BLAST back'></a>\n",
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Blast hits back against the genomes###\n",
      "---\n",
      "\n",
      "Next we will blast all the sequences from our first BLAST run back against the _S. PCC 7942_ or _S. PCC 6803_ genome to validate to correctness of our first run. Only hits that align to the original protein are considered a 'real' hit.\n",
      "\n",
      "e.g.: If you first blasted kaiA _(Synpcc_7942_1218)_ against the 'nr' database. You would blast every hit you got in this analysis back against the _Synechococcus elongatus PCC 7942_ genome. Now you get for every hit, just one hit in the genome. Next you would filter only these hits that match with kaiA.\n",
      "\n",
      "I ran this analysis using the standalone local BLAST from the command line, b/c I had problems with the NCBI server. Installation information for BLAST can be found [here](http://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download). Following is the command line script you need to run for reproduction of my results. I also attached the python script I used before to run BLAST on the NCBI server."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# Command line code for standalone local BLAST run\n",
      "\n",
      "# For more information about the blastp options\n",
      "blastp -help\n",
      "\n",
      "# Build your own BLAST database from the genome file\n",
      "# -in: Input fasta file\n",
      "# -dbtype: Database type, either nucleotide or protein\n",
      "# -out: Database name\n",
      "makeblastdb -in Synechocystis_chr_prot.faa -dbtype 'prot' -out Synechocystis_chr_prot\n",
      "\n",
      "# Run BLAST for a set of input files\n",
      "# -query: Input file\n",
      "# -db: Database of your BLAST run\n",
      "# -out: Output file name\n",
      "# -evalue: Expectation value (E) threshold for saving hits. Default = 10\n",
      "# -word_size: Word size for wordfinder algorithm\n",
      "# -outfmt: alignment view options:\n",
      "     0 = pairwise,\n",
      "     1 = query-anchored showing identities,\n",
      "     2 = query-anchored no identities,\n",
      "     3 = flat query-anchored, show identities,\n",
      "     4 = flat query-anchored, no identities,\n",
      "     5 = XML Blast output,\n",
      "     6 = tabular,\n",
      "     7 = tabular with comment lines,\n",
      "     8 = Text ASN.1,\n",
      "     9 = Binary ASN.1,\n",
      "    10 = Comma-separated values,\n",
      "    11 = BLAST archive format (ASN.1) \n",
      "    12 = JSON Seqalign output\n",
      "# -num_alingments: Number of database sequences to show alignments for. Default = 250\n",
      "\n",
      "blastp -query seq/D1_BLAST.faa -db Synechocystis_chr_prot -out D1.xml -evalue 10 -word_size 3 -outfmt 5 -num_alignments 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='CSV'></a>\n",
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###CSV with hits###\n",
      "---\n",
      "\n",
      "For further analysis and visualization we want our data to be in a more general format. I prefer the CSV format, b/c I'm so used to it from working with Excel and it is easy to work with considering the python package __pandas__. \n",
      "For the ones not familiar with the CSV (comma separated values) format. It's a spreadsheet plain text. Each field it separated by a specific delimiter, in most cases it a comma. If your using the comma as a decimal separator (Europe) semicolon is the standard field delimiter. For more information check the [wikipedia page](http://en.wikipedia.org/wiki/Comma-separated_values).\n",
      "\n",
      "####Input/Output####\n",
      "Input:     \n",
      "gnl|BL_ORD_ID|1449 gi|81300261|ref|YP_400469.1| DNA repair protein RadA [Synechococcus elongatus PCC 7942]     \n",
      "Output:     \n",
      "Synechococcus , elongatus PCC 7942 , DNA repair protein RadA , 81300261 , ...   \n",
      "\n",
      "To achieve this I needed to do a couple of replacing, spliting and joining steps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the BLAST XML file and load it into the NCBIXML.parser.\n",
      "result_handle = open('D1.xml')\n",
      "blast_records = NCBIXML.parse(result_handle)\n",
      "\n",
      "# Open a CSV file and write the header in the first line.\n",
      "csv = open('D1_hits.csv','w')\n",
      "csv.write('query name,query organism name,query strain name,query gene name,query gi,query gene length,e value,Identity [%],database species name,database gene name,database gi,database gene length \\n')\n",
      "\n",
      "# Loop over every record in your XML and count them.\n",
      "for blast_record in blast_records:\n",
      "    \n",
      "    # Check the GI for the alignment. If the hit matches your protein of interest write an entry in the CSV file.\n",
      "    for alignment in blast_record.alignments:\n",
      "            \n",
      "        # Some hits contain 'MULTISPECIES' entries. Loop over each organism in the query title.\n",
      "        for i in blast_record.query.split(' >', blast_record.query.count('>')):\n",
      "            # Organisms names are enclosed by square bracktes and we only want to keep these hits.\n",
      "            if '[' in i:\n",
      "                    \n",
      "                # Extract name\n",
      "                csv.write(i.split('[',1)[1][0:-1].replace(',',' ').replace(\"'\",'').replace('[','').replace(']','').lstrip())\n",
      "                csv.write(',')\n",
      "                    \n",
      "                # Extract species name\n",
      "                csv.write(i.split('[',1)[1][0:-1].replace(',',' ').replace(\"'\",'').replace('[','').replace(']','').lstrip().split(' ',i.split('[',1)[1][0:-1].count(' '))[0])\n",
      "                csv.write(',')\n",
      "                    \n",
      "                # Extract strain name\n",
      "                csv.write(' '.join(i.split('[',1)[1][0:-1].replace(',',' ').replace('[','').replace(']','').lstrip().split(' ',i.split('[',1)[1][0:-1].count(' '))[1:]))\n",
      "                csv.write(',')\n",
      "                    \n",
      "                # Extract gene name\n",
      "                csv.write(str(i.split('|',5)[4].split('[',1)[0].replace(',',' ')[1:]))\n",
      "                csv.write(',')\n",
      "                    \n",
      "                # Extract GI of that gene\n",
      "                csv.write(str(i.split('|',2)[1]))\n",
      "                csv.write(',')\n",
      "                for hsp in alignment.hsps:\n",
      "                    \n",
      "                    # Extract gene length\n",
      "                    csv.write(str(blast_record.query_length))\n",
      "                    csv.write(',')\n",
      "                        \n",
      "                    # Extract e-value of that hit\n",
      "                    csv.write(str(hsp.expect))\n",
      "                    csv.write(',')\n",
      "                        \n",
      "                    # Calculate identity [%] for that hit\n",
      "                    csv.write(str(((hsp.identities/float(len(hsp.match)))*100)))\n",
      "                    csv.write(',')\n",
      "                        \n",
      "                    # Extract SyPCC7942 or SyPCC6803 organims name\n",
      "                    csv.write(alignment.title.split('[',1)[1][0:-1])\n",
      "                    csv.write(',')\n",
      "                        \n",
      "                    # Extract SyPCC7942 or SyPCC6803 gene name\n",
      "                    csv.write(alignment.title.split('|',7)[6].split('[',1)[0])\n",
      "                    csv.write(',')\n",
      "                        \n",
      "                    # Extract SyPCC7942 or SyPCC6803 GI for that gene\n",
      "                    csv.write(alignment.title.split('|',4)[3])\n",
      "                    csv.write(',')\n",
      "                        \n",
      "                    # Extract SyPCC7942 or SyPCC6803 gene length\n",
      "                    csv.write(str(alignment.length))\n",
      "                    csv.write('\\n')\n",
      "                        \n",
      "                    break\n",
      "\n",
      "csv.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}